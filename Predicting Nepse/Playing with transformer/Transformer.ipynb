{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7dab9f53",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\AppData\\Local\\Temp\\ipykernel_17992\\2001187912.py:4: DeprecationWarning: `import kerastuner` is deprecated, please use `import keras_tuner`.\n",
      "  from kerastuner import RandomSearch\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from kerastuner import RandomSearch\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping, TensorBoard "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78add3d3",
   "metadata": {},
   "source": [
    "### Preparing train and val dataset for LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d027d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to the train and validation datasets\n",
    "train_data_path = 'train_data.csv'  \n",
    "val_data_path = 'val_data.csv'  \n",
    "test_data_path = 'test_data.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59454ede",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2791, 1981)\n",
      "(931, 1981)\n"
     ]
    }
   ],
   "source": [
    "# Load the datasets\n",
    "train_data = pd.read_csv(train_data_path)\n",
    "val_data = pd.read_csv(val_data_path)\n",
    "test_data = pd.read_csv(test_data_path)\n",
    "print(train_data.shape)\n",
    "print(val_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dae8e7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the datasets into features (X) and target (y)\n",
    "X_train = train_data.drop('Output', axis=1)\n",
    "y_train = train_data['Output']\n",
    "X_val = val_data.drop('Output', axis=1)\n",
    "y_val = val_data['Output']\n",
    "X_test = test_data.drop('Output', axis=1)\n",
    "y_test = test_data['Output']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29d302c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (2791, 1980)\n",
      "y_train shape: (2791,)\n",
      "X_val shape: (931, 1980)\n",
      "y_val shape: (931,)\n",
      "X_test shape: (931, 1980)\n",
      "y_test shape: (931,)\n"
     ]
    }
   ],
   "source": [
    "# Check the shapes of the datasets\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"X_val shape:\", X_val.shape)\n",
    "print(\"y_val shape:\", y_val.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_test shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c210d5ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      0.080714\n",
      "1      0.687701\n",
      "2      0.019128\n",
      "3      0.191419\n",
      "4      0.391193\n",
      "         ...   \n",
      "926    0.470977\n",
      "927    0.183726\n",
      "928    0.029032\n",
      "929    0.089227\n",
      "930    0.197472\n",
      "Name: Output, Length: 931, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print (y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c88527",
   "metadata": {},
   "source": [
    "### Reshaping the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "030425ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f2a17b35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assuming an equal number of features per day\n",
    "num_days = 60\n",
    "total_features = 1980\n",
    "features_per_day = int(total_features / num_days)\n",
    "features_per_day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ee7731b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the data to (samples, time steps, features)\n",
    "X_train_reshaped = X_train.values.reshape(-1, num_days, features_per_day)\n",
    "X_val_reshaped = X_val.values.reshape(-1, num_days, features_per_day)\n",
    "X_test_reshaped = X_test.values.reshape(-1, num_days, features_per_day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "66342671",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[8.77508802e-01 8.75963586e-01 8.74107413e-01 ... 0.00000000e+00\n",
      "   0.00000000e+00 0.00000000e+00]\n",
      "  [8.83411306e-01 8.85684264e-01 8.85258435e-01 ... 0.00000000e+00\n",
      "   0.00000000e+00 0.00000000e+00]\n",
      "  [8.47678380e-01 8.68316151e-01 8.60032794e-01 ... 0.00000000e+00\n",
      "   0.00000000e+00 0.00000000e+00]\n",
      "  ...\n",
      "  [6.42186773e-01 6.40862657e-01 6.39483947e-01 ... 0.00000000e+00\n",
      "   0.00000000e+00 0.00000000e+00]\n",
      "  [6.67746895e-01 6.62961532e-01 6.49134702e-01 ... 0.00000000e+00\n",
      "   0.00000000e+00 0.00000000e+00]\n",
      "  [6.87238444e-01 7.00086699e-01 6.76880022e-01 ... 0.00000000e+00\n",
      "   0.00000000e+00 0.00000000e+00]]\n",
      "\n",
      " [[3.84374500e-02 3.66728240e-02 3.22461207e-02 ... 0.00000000e+00\n",
      "   0.00000000e+00 0.00000000e+00]\n",
      "  [3.94101290e-02 3.78413780e-02 3.96176240e-02 ... 0.00000000e+00\n",
      "   0.00000000e+00 0.00000000e+00]\n",
      "  [3.85370899e-02 3.68141810e-02 3.72662445e-02 ... 0.00000000e+00\n",
      "   0.00000000e+00 0.00000000e+00]\n",
      "  ...\n",
      "  [3.46843300e-03 1.99313900e-03 7.83793000e-04 ... 0.00000000e+00\n",
      "   1.00000000e+00 0.00000000e+00]\n",
      "  [1.28109000e-03 3.02976000e-03 2.02920700e-03 ... 0.00000000e+00\n",
      "   1.00000000e+00 0.00000000e+00]\n",
      "  [4.18489500e-03 2.64338400e-03 1.26945700e-03 ... 0.00000000e+00\n",
      "   1.00000000e+00 0.00000000e+00]]\n",
      "\n",
      " [[7.20115010e-02 7.30723560e-02 7.39410380e-02 ... 0.00000000e+00\n",
      "   0.00000000e+00 0.00000000e+00]\n",
      "  [7.86114880e-02 7.63424240e-02 7.27196660e-02 ... 0.00000000e+00\n",
      "   0.00000000e+00 0.00000000e+00]\n",
      "  [8.70477040e-02 8.47202070e-02 8.19376520e-02 ... 0.00000000e+00\n",
      "   0.00000000e+00 0.00000000e+00]\n",
      "  ...\n",
      "  [1.83243340e-02 1.72079080e-02 1.77964349e-02 ... 0.00000000e+00\n",
      "   0.00000000e+00 0.00000000e+00]\n",
      "  [2.12945650e-02 1.99172588e-02 1.80032020e-02 ... 0.00000000e+00\n",
      "   0.00000000e+00 0.00000000e+00]\n",
      "  [2.31497740e-02 2.20847390e-02 2.12153123e-02 ... 0.00000000e+00\n",
      "   0.00000000e+00 0.00000000e+00]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[3.99918390e-01 4.04253916e-01 3.98825753e-01 ... 0.00000000e+00\n",
      "   0.00000000e+00 0.00000000e+00]\n",
      "  [3.75036772e-01 3.94867784e-01 3.81038935e-01 ... 0.00000000e+00\n",
      "   0.00000000e+00 0.00000000e+00]\n",
      "  [3.71278908e-01 3.74121228e-01 3.68892543e-01 ... 0.00000000e+00\n",
      "   0.00000000e+00 0.00000000e+00]\n",
      "  ...\n",
      "  [4.07941810e-01 4.03391635e-01 3.99864399e-01 ... 0.00000000e+00\n",
      "   0.00000000e+00 0.00000000e+00]\n",
      "  [4.10826635e-01 4.09507699e-01 4.11332785e-01 ... 0.00000000e+00\n",
      "   0.00000000e+00 0.00000000e+00]\n",
      "  [4.07970279e-01 4.11265243e-01 4.07649438e-01 ... 0.00000000e+00\n",
      "   0.00000000e+00 0.00000000e+00]]\n",
      "\n",
      " [[6.43724080e-02 6.28380800e-02 6.28669520e-02 ... 0.00000000e+00\n",
      "   0.00000000e+00 0.00000000e+00]\n",
      "  [7.02037410e-02 6.79929130e-02 6.67185990e-02 ... 0.00000000e+00\n",
      "   0.00000000e+00 0.00000000e+00]\n",
      "  [6.84434280e-02 6.84970880e-02 6.76081800e-02 ... 0.00000000e+00\n",
      "   0.00000000e+00 0.00000000e+00]\n",
      "  ...\n",
      "  [2.35815485e-02 3.22907439e-02 2.48601915e-02 ... 0.00000000e+00\n",
      "   0.00000000e+00 0.00000000e+00]\n",
      "  [1.62271420e-02 1.63974590e-02 1.66952780e-02 ... 0.00000000e+00\n",
      "   0.00000000e+00 0.00000000e+00]\n",
      "  [1.88367700e-02 1.69817366e-02 1.66087240e-02 ... 0.00000000e+00\n",
      "   0.00000000e+00 0.00000000e+00]]\n",
      "\n",
      " [[1.72169028e-01 1.70302693e-01 1.68736746e-01 ... 0.00000000e+00\n",
      "   0.00000000e+00 0.00000000e+00]\n",
      "  [1.74104898e-01 1.74618806e-01 1.71915196e-01 ... 0.00000000e+00\n",
      "   0.00000000e+00 0.00000000e+00]\n",
      "  [1.63528787e-01 1.69756111e-01 1.66289196e-01 ... 0.00000000e+00\n",
      "   0.00000000e+00 0.00000000e+00]\n",
      "  ...\n",
      "  [2.58111199e-01 2.54664794e-01 2.57464068e-01 ... 0.00000000e+00\n",
      "   0.00000000e+00 0.00000000e+00]\n",
      "  [2.58391141e-01 2.54956933e-01 2.59536552e-01 ... 0.00000000e+00\n",
      "   0.00000000e+00 0.00000000e+00]\n",
      "  [2.53964262e-01 2.54443335e-01 2.57834326e-01 ... 0.00000000e+00\n",
      "   0.00000000e+00 0.00000000e+00]]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train_reshaped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a4f87421",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_reshaped shape: (2791, 60, 33)\n",
      "y_train shape: (2791,)\n",
      "X_val_reshaped shape: (931, 60, 33)\n",
      "y_val: (931,)\n",
      "X_test_reshaped shape: (931, 60, 33)\n",
      "y_test shape: (931,)\n"
     ]
    }
   ],
   "source": [
    "# Check the shapes of the datasets\n",
    "print(\"X_train_reshaped shape:\", X_train_reshaped.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"X_val_reshaped shape:\", X_val_reshaped.shape)\n",
    "print(\"y_val:\", y_val.shape)\n",
    "print(\"X_test_reshaped shape:\", X_test_reshaped.shape)\n",
    "print(\"y_test shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ccdb6aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your batch size\n",
    "batch_size = 32  # You can adjust this according to your needs\n",
    "\n",
    "# Convert to TensorFlow datasets\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((X_train_reshaped, y_train)).shuffle(len(X_train_reshaped)).batch(batch_size)\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((X_val_reshaped, y_val)).batch(batch_size)\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((X_test_reshaped, y_test)).batch(batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "024ab35b",
   "metadata": {},
   "source": [
    "### Building transformer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b7b2f15f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def positional_encoding(position, d_model):\n",
    "    def get_angles(pos, i, d_model):\n",
    "        angles = 1 / tf.pow(10000, (2 * (i // 2)) / tf.cast(d_model, tf.float32))\n",
    "        return pos * angles\n",
    "\n",
    "    position = tf.range(position, dtype=tf.float32)[:, tf.newaxis]\n",
    "    i = tf.range(d_model, dtype=tf.float32)[tf.newaxis, :]\n",
    "\n",
    "    angle_rads = get_angles(position, i, d_model)\n",
    "\n",
    "    # Apply sin to even indices in the array; 2i\n",
    "    sines = tf.math.sin(angle_rads[:, 0::2])\n",
    "\n",
    "    # Apply cos to odd indices in the array; 2i+1\n",
    "    cosines = tf.math.cos(angle_rads[:, 1::2])\n",
    "\n",
    "    pos_encoding = tf.concat([sines, cosines], axis=-1)\n",
    "    pos_encoding = pos_encoding[tf.newaxis, ...]\n",
    "    return tf.cast(pos_encoding, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b3ba4bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "\n",
    "        assert d_model % self.num_heads == 0\n",
    "\n",
    "        self.depth = d_model // self.num_heads\n",
    "\n",
    "        self.wq = tf.keras.layers.Dense(d_model)\n",
    "        self.wk = tf.keras.layers.Dense(d_model)\n",
    "        self.wv = tf.keras.layers.Dense(d_model)\n",
    "\n",
    "        self.dense = tf.keras.layers.Dense(d_model)\n",
    "\n",
    "    def split_heads(self, x, batch_size):\n",
    "        # Split the last dimension into (num_heads, depth)\n",
    "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
    "        # Transpose for shape (batch_size, num_heads, seq_len, depth)\n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "    \n",
    "    def call(self, v, k, q, mask):\n",
    "        batch_size = tf.shape(q)[0]\n",
    "\n",
    "        # Linear layers\n",
    "        q = self.wq(q)  # (batch_size, seq_len, d_model)\n",
    "        k = self.wk(k)\n",
    "        v = self.wv(v)\n",
    "\n",
    "        # Debugging: Print shapes after linear transformation\n",
    "        #print(\"Shapes after linear transformation:\", q.shape, k.shape, v.shape)\n",
    "\n",
    "        # Split heads\n",
    "        q = self.split_heads(q, batch_size)\n",
    "        k = self.split_heads(k, batch_size)\n",
    "        v = self.split_heads(v, batch_size)\n",
    "\n",
    "        # Debugging: Print shapes after split_heads\n",
    "        #print(\"Shapes after split_heads:\", q.shape, k.shape, v.shape)\n",
    "\n",
    "        # Scaled dot-product attention\n",
    "        scaled_attention, attention_weights = scaled_dot_product_attention(q, k, v, mask)\n",
    "        # (batch_size, num_heads, seq_len_q, depth), (batch_size, num_heads, seq_len_q, seq_len_k)\n",
    "\n",
    "        # Concatenate heads\n",
    "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
    "        concat_attention = tf.reshape(scaled_attention, (batch_size, -1, self.d_model))\n",
    "\n",
    "        # Final linear layer\n",
    "        output = self.dense(concat_attention)\n",
    "\n",
    "        return output, attention_weights\n",
    "    \n",
    "    def scaled_dot_product_attention(q, k, v, mask):\n",
    "        matmul_qk = tf.matmul(q, k, transpose_b=True)\n",
    "        dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
    "        scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
    "        if mask is not None:\n",
    "            scaled_attention_logits += (mask * -1e9)  \n",
    "        attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)\n",
    "        output = tf.matmul(attention_weights, v)\n",
    "        return output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bb626744",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pointwise_feed_forward_network(d_model, dff):\n",
    "    return tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(dff, activation='relu'),\n",
    "        tf.keras.layers.Dense(d_model)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9276a5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "\n",
    "        self.mha = MultiHeadAttention(d_model, num_heads)\n",
    "        self.ffn = pointwise_feed_forward_network(d_model, dff)\n",
    "\n",
    "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
    "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
    "\n",
    "    def call(self, x, training, mask):\n",
    "        attn_output, _ = self.mha(x, x, x, mask)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(x + attn_output)\n",
    "\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        out2 = self.layernorm2(out1 + ffn_output)\n",
    "\n",
    "        return out2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3b7b2b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "\n",
    "        self.mha1 = MultiHeadAttention(d_model, num_heads)\n",
    "        self.mha2 = MultiHeadAttention(d_model, num_heads)\n",
    "\n",
    "        self.ffn = pointwise_feed_forward_network(d_model, dff)\n",
    "\n",
    "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
    "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
    "        self.dropout3 = tf.keras.layers.Dropout(rate)\n",
    "\n",
    "    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n",
    "        attn1, attn_weights_block1 = self.mha1(x, x, x, look_ahead_mask)\n",
    "        attn1 = self.dropout1(attn1, training=training)\n",
    "        out1 = self.layernorm1(attn1 + x)\n",
    "\n",
    "        attn2, attn_weights_block2 = self.mha2(enc_output, enc_output, out1, padding_mask)\n",
    "        attn2 = self.dropout2(attn2, training=training)\n",
    "        out2 = self.layernorm2(attn2 + out1)\n",
    "\n",
    "        ffn_output = self.ffn(out2)\n",
    "        ffn_output = self.dropout3(ffn_output, training=training)\n",
    "        out3 = self.layernorm3(ffn_output + out2)\n",
    "\n",
    "        return out3, attn_weights_block1, attn_weights_block2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8bab26e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeSeriesTransformer(tf.keras.Model):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, rate=0.1):\n",
    "        super(TimeSeriesTransformer, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        # Input processing\n",
    "        self.input_layer = tf.keras.layers.Dense(d_model, activation='relu')\n",
    "        self.pos_encoding = positional_encoding(60, d_model)  # 60 time steps\n",
    "\n",
    "        # Encoder Layers\n",
    "        self.enc_layers = [EncoderLayer(d_model, num_heads, dff, rate) for _ in range(num_layers)]\n",
    "\n",
    "        # Decoder Layers\n",
    "        self.dec_layers = [DecoderLayer(d_model, num_heads, dff, rate) for _ in range(num_layers)]\n",
    "\n",
    "        # Final Output Layer\n",
    "        self.final_layer = tf.keras.layers.Dense(1)  # Predicting a single value\n",
    "\n",
    "    def call(self, x, training=False):\n",
    "        seq_len = tf.shape(x)[1]\n",
    "\n",
    "        # Example default masks (adjust as needed)\n",
    "        look_ahead_mask = None  # or create a suitable look ahead mask\n",
    "        padding_mask = None  # or create a suitable padding mask\n",
    "        \n",
    "        # Input processing\n",
    "        x = self.input_layer(x)  # (batch_size, seq_len, d_model)\n",
    "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "        x += self.pos_encoding[:, :seq_len, :]\n",
    "\n",
    "        # Encoder\n",
    "        for i in range(self.num_layers):\n",
    "            x = self.enc_layers[i](x, training, padding_mask)\n",
    "\n",
    "        encoder_output = x  # (batch_size, input_seq_len, d_model)\n",
    "\n",
    "        # Decoder\n",
    "        decoder_output = encoder_output  # Adjust as needed\n",
    "        for i in range(self.num_layers):\n",
    "            decoder_output = self.dec_layers[i](decoder_output, encoder_output, training, look_ahead_mask, padding_mask)\n",
    "\n",
    "        # Final Output\n",
    "        final_output = self.final_layer(decoder_output)  # (batch_size, seq_len, 1)\n",
    "\n",
    "        return final_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1398ca2",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b53328e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading Tuner from transformer_tuning\\stock_prediction\\tuner0.json\n",
      "\n",
      "Search: Running Trial #3\n",
      "\n",
      "Value             |Best Value So Far |Hyperparameter\n",
      "5                 |4                 |num_layers\n",
      "384               |128               |d_model\n",
      "8                 |2                 |num_heads\n",
      "2048              |1152              |dff\n",
      "0.2               |0.5               |rate\n",
      "2                 |2                 |tuner/epochs\n",
      "0                 |0                 |tuner/initial_epoch\n",
      "2                 |2                 |tuner/bracket\n",
      "0                 |0                 |tuner/round\n",
      "\n",
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras_tuner\\src\\engine\\base_tuner.py\", line 273, in _try_run_and_update_trial\n",
      "    self._run_and_update_trial(trial, *fit_args, **fit_kwargs)\n",
      "  File \"C:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras_tuner\\src\\engine\\base_tuner.py\", line 238, in _run_and_update_trial\n",
      "    results = self.run_trial(trial, *fit_args, **fit_kwargs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras_tuner\\src\\tuners\\hyperband.py\", line 427, in run_trial\n",
      "    return super().run_trial(trial, *fit_args, **fit_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras_tuner\\src\\engine\\tuner.py\", line 314, in run_trial\n",
      "    obj_value = self._build_and_fit_model(trial, *args, **copied_kwargs)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras_tuner\\src\\engine\\tuner.py\", line 233, in _build_and_fit_model\n",
      "    results = self.hypermodel.fit(hp, model, *args, **kwargs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras_tuner\\src\\engine\\hypermodel.py\", line 149, in fit\n",
      "    return model.fit(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 70, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"C:\\Users\\lenovo\\AppData\\Local\\Temp\\__autograph_generated_filev788uc8h.py\", line 18, in tf__train_function\n",
      "    raise\n",
      "  File \"C:\\Users\\lenovo\\AppData\\Local\\Temp\\__autograph_generated_filec5ox0ws4.py\", line 31, in tf__call\n",
      "    ag__.for_stmt(ag__.converted_call(ag__.ld(range), (ag__.ld(self).num_layers,), None, fscope), None, loop_body, get_state, set_state, ('x',), {'iterate_names': 'i'})\n",
      "  File \"C:\\Users\\lenovo\\AppData\\Local\\Temp\\__autograph_generated_filec5ox0ws4.py\", line 29, in loop_body\n",
      "    x = ag__.converted_call(ag__.ld(self).enc_layers[ag__.ld(i)], (ag__.ld(x), ag__.ld(training), ag__.ld(padding_mask)), None, fscope)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\lenovo\\AppData\\Local\\Temp\\__autograph_generated_fileiznkj8k3.py\", line 10, in tf__call\n",
      "    attn_output, _ = ag__.converted_call(ag__.ld(self).mha, (ag__.ld(x), ag__.ld(x), ag__.ld(x), ag__.ld(mask)), None, fscope)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\lenovo\\AppData\\Local\\Temp\\__autograph_generated_file57nxcwqz.py\", line 17, in tf__call\n",
      "    scaled_attention, attention_weights = ag__.converted_call(ag__.ld(scaled_dot_product_attention), (ag__.ld(q), ag__.ld(k), ag__.ld(v), ag__.ld(mask)), None, fscope)\n",
      "                                                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "NameError: in user code:\n",
      "\n",
      "    File \"C:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1338, in train_function  *\n",
      "        return step_function(self, iterator)\n",
      "    File \"C:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1322, in step_function  **\n",
      "        outputs = model.distribute_strategy.run(run_step, args=(data,))\n",
      "    File \"C:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1303, in run_step  **\n",
      "        outputs = model.train_step(data)\n",
      "    File \"C:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1080, in train_step\n",
      "        y_pred = self(x, training=True)\n",
      "    File \"C:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 70, in error_handler\n",
      "        raise e.with_traceback(filtered_tb) from None\n",
      "    File \"C:\\Users\\lenovo\\AppData\\Local\\Temp\\__autograph_generated_filec5ox0ws4.py\", line 31, in tf__call\n",
      "        ag__.for_stmt(ag__.converted_call(ag__.ld(range), (ag__.ld(self).num_layers,), None, fscope), None, loop_body, get_state, set_state, ('x',), {'iterate_names': 'i'})\n",
      "    File \"C:\\Users\\lenovo\\AppData\\Local\\Temp\\__autograph_generated_filec5ox0ws4.py\", line 29, in loop_body\n",
      "        x = ag__.converted_call(ag__.ld(self).enc_layers[ag__.ld(i)], (ag__.ld(x), ag__.ld(training), ag__.ld(padding_mask)), None, fscope)\n",
      "    File \"C:\\Users\\lenovo\\AppData\\Local\\Temp\\__autograph_generated_fileiznkj8k3.py\", line 10, in tf__call\n",
      "        attn_output, _ = ag__.converted_call(ag__.ld(self).mha, (ag__.ld(x), ag__.ld(x), ag__.ld(x), ag__.ld(mask)), None, fscope)\n",
      "    File \"C:\\Users\\lenovo\\AppData\\Local\\Temp\\__autograph_generated_file57nxcwqz.py\", line 17, in tf__call\n",
      "        scaled_attention, attention_weights = ag__.converted_call(ag__.ld(scaled_dot_product_attention), (ag__.ld(q), ag__.ld(k), ag__.ld(v), ag__.ld(mask)), None, fscope)\n",
      "\n",
      "    NameError: Exception encountered when calling layer 'time_series_transformer' (type TimeSeriesTransformer).\n",
      "    \n",
      "    in user code:\n",
      "    \n",
      "        File \"C:\\Users\\lenovo\\AppData\\Local\\Temp\\ipykernel_17992\\2425982286.py\", line 35, in call  *\n",
      "            x = self.enc_layers[i](x, training, padding_mask)\n",
      "        File \"C:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 70, in error_handler  **\n",
      "            raise e.with_traceback(filtered_tb) from None\n",
      "        File \"C:\\Users\\lenovo\\AppData\\Local\\Temp\\__autograph_generated_fileiznkj8k3.py\", line 10, in tf__call\n",
      "            attn_output, _ = ag__.converted_call(ag__.ld(self).mha, (ag__.ld(x), ag__.ld(x), ag__.ld(x), ag__.ld(mask)), None, fscope)\n",
      "        File \"C:\\Users\\lenovo\\AppData\\Local\\Temp\\__autograph_generated_file57nxcwqz.py\", line 17, in tf__call\n",
      "            scaled_attention, attention_weights = ag__.converted_call(ag__.ld(scaled_dot_product_attention), (ag__.ld(q), ag__.ld(k), ag__.ld(v), ag__.ld(mask)), None, fscope)\n",
      "    \n",
      "        NameError: Exception encountered when calling layer 'encoder_layer' (type EncoderLayer).\n",
      "        \n",
      "        in user code:\n",
      "        \n",
      "            File \"C:\\Users\\lenovo\\AppData\\Local\\Temp\\ipykernel_17992\\3993560056.py\", line 15, in call  *\n",
      "                attn_output, _ = self.mha(x, x, x, mask)\n",
      "            File \"C:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 70, in error_handler  **\n",
      "                raise e.with_traceback(filtered_tb) from None\n",
      "            File \"C:\\Users\\lenovo\\AppData\\Local\\Temp\\__autograph_generated_file57nxcwqz.py\", line 17, in tf__call\n",
      "                scaled_attention, attention_weights = ag__.converted_call(ag__.ld(scaled_dot_product_attention), (ag__.ld(q), ag__.ld(k), ag__.ld(v), ag__.ld(mask)), None, fscope)\n",
      "        \n",
      "            NameError: Exception encountered when calling layer 'multi_head_attention' (type MultiHeadAttention).\n",
      "            \n",
      "            in user code:\n",
      "            \n",
      "                File \"C:\\Users\\lenovo\\AppData\\Local\\Temp\\ipykernel_17992\\2737509367.py\", line 43, in call  *\n",
      "                    scaled_attention, attention_weights = scaled_dot_product_attention(q, k, v, mask)\n",
      "            \n",
      "                NameError: name 'scaled_dot_product_attention' is not defined\n",
      "            \n",
      "            \n",
      "            Call arguments received by layer 'multi_head_attention' (type MultiHeadAttention):\n",
      "              • v=tf.Tensor(shape=(None, 60, 384), dtype=float32)\n",
      "              • k=tf.Tensor(shape=(None, 60, 384), dtype=float32)\n",
      "              • q=tf.Tensor(shape=(None, 60, 384), dtype=float32)\n",
      "              • mask=None\n",
      "        \n",
      "        \n",
      "        Call arguments received by layer 'encoder_layer' (type EncoderLayer):\n",
      "          • x=tf.Tensor(shape=(None, 60, 384), dtype=float32)\n",
      "          • training=True\n",
      "          • mask=None\n",
      "    \n",
      "    \n",
      "    Call arguments received by layer 'time_series_transformer' (type TimeSeriesTransformer):\n",
      "      • x=tf.Tensor(shape=(None, 60, 33), dtype=float32)\n",
      "      • training=True\n",
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Number of consecutive failures exceeded the limit of 3.\nTraceback (most recent call last):\n  File \"C:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras_tuner\\src\\engine\\base_tuner.py\", line 273, in _try_run_and_update_trial\n    self._run_and_update_trial(trial, *fit_args, **fit_kwargs)\n  File \"C:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras_tuner\\src\\engine\\base_tuner.py\", line 238, in _run_and_update_trial\n    results = self.run_trial(trial, *fit_args, **fit_kwargs)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras_tuner\\src\\tuners\\hyperband.py\", line 427, in run_trial\n    return super().run_trial(trial, *fit_args, **fit_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras_tuner\\src\\engine\\tuner.py\", line 314, in run_trial\n    obj_value = self._build_and_fit_model(trial, *args, **copied_kwargs)\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras_tuner\\src\\engine\\tuner.py\", line 233, in _build_and_fit_model\n    results = self.hypermodel.fit(hp, model, *args, **kwargs)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras_tuner\\src\\engine\\hypermodel.py\", line 149, in fit\n    return model.fit(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 70, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n  File \"C:\\Users\\lenovo\\AppData\\Local\\Temp\\__autograph_generated_filev788uc8h.py\", line 18, in tf__train_function\n    raise\n  File \"C:\\Users\\lenovo\\AppData\\Local\\Temp\\__autograph_generated_filec5ox0ws4.py\", line 31, in tf__call\n    ag__.for_stmt(ag__.converted_call(ag__.ld(range), (ag__.ld(self).num_layers,), None, fscope), None, loop_body, get_state, set_state, ('x',), {'iterate_names': 'i'})\n  File \"C:\\Users\\lenovo\\AppData\\Local\\Temp\\__autograph_generated_filec5ox0ws4.py\", line 29, in loop_body\n    x = ag__.converted_call(ag__.ld(self).enc_layers[ag__.ld(i)], (ag__.ld(x), ag__.ld(training), ag__.ld(padding_mask)), None, fscope)\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\lenovo\\AppData\\Local\\Temp\\__autograph_generated_fileiznkj8k3.py\", line 10, in tf__call\n    attn_output, _ = ag__.converted_call(ag__.ld(self).mha, (ag__.ld(x), ag__.ld(x), ag__.ld(x), ag__.ld(mask)), None, fscope)\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\lenovo\\AppData\\Local\\Temp\\__autograph_generated_file57nxcwqz.py\", line 17, in tf__call\n    scaled_attention, attention_weights = ag__.converted_call(ag__.ld(scaled_dot_product_attention), (ag__.ld(q), ag__.ld(k), ag__.ld(v), ag__.ld(mask)), None, fscope)\n                                                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nNameError: in user code:\n\n    File \"C:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1338, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1322, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1303, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1080, in train_step\n        y_pred = self(x, training=True)\n    File \"C:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\lenovo\\AppData\\Local\\Temp\\__autograph_generated_filec5ox0ws4.py\", line 31, in tf__call\n        ag__.for_stmt(ag__.converted_call(ag__.ld(range), (ag__.ld(self).num_layers,), None, fscope), None, loop_body, get_state, set_state, ('x',), {'iterate_names': 'i'})\n    File \"C:\\Users\\lenovo\\AppData\\Local\\Temp\\__autograph_generated_filec5ox0ws4.py\", line 29, in loop_body\n        x = ag__.converted_call(ag__.ld(self).enc_layers[ag__.ld(i)], (ag__.ld(x), ag__.ld(training), ag__.ld(padding_mask)), None, fscope)\n    File \"C:\\Users\\lenovo\\AppData\\Local\\Temp\\__autograph_generated_fileiznkj8k3.py\", line 10, in tf__call\n        attn_output, _ = ag__.converted_call(ag__.ld(self).mha, (ag__.ld(x), ag__.ld(x), ag__.ld(x), ag__.ld(mask)), None, fscope)\n    File \"C:\\Users\\lenovo\\AppData\\Local\\Temp\\__autograph_generated_file57nxcwqz.py\", line 17, in tf__call\n        scaled_attention, attention_weights = ag__.converted_call(ag__.ld(scaled_dot_product_attention), (ag__.ld(q), ag__.ld(k), ag__.ld(v), ag__.ld(mask)), None, fscope)\n\n    NameError: Exception encountered when calling layer 'time_series_transformer' (type TimeSeriesTransformer).\n    \n    in user code:\n    \n        File \"C:\\Users\\lenovo\\AppData\\Local\\Temp\\ipykernel_17992\\2425982286.py\", line 35, in call  *\n            x = self.enc_layers[i](x, training, padding_mask)\n        File \"C:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 70, in error_handler  **\n            raise e.with_traceback(filtered_tb) from None\n        File \"C:\\Users\\lenovo\\AppData\\Local\\Temp\\__autograph_generated_fileiznkj8k3.py\", line 10, in tf__call\n            attn_output, _ = ag__.converted_call(ag__.ld(self).mha, (ag__.ld(x), ag__.ld(x), ag__.ld(x), ag__.ld(mask)), None, fscope)\n        File \"C:\\Users\\lenovo\\AppData\\Local\\Temp\\__autograph_generated_file57nxcwqz.py\", line 17, in tf__call\n            scaled_attention, attention_weights = ag__.converted_call(ag__.ld(scaled_dot_product_attention), (ag__.ld(q), ag__.ld(k), ag__.ld(v), ag__.ld(mask)), None, fscope)\n    \n        NameError: Exception encountered when calling layer 'encoder_layer' (type EncoderLayer).\n        \n        in user code:\n        \n            File \"C:\\Users\\lenovo\\AppData\\Local\\Temp\\ipykernel_17992\\3993560056.py\", line 15, in call  *\n                attn_output, _ = self.mha(x, x, x, mask)\n            File \"C:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 70, in error_handler  **\n                raise e.with_traceback(filtered_tb) from None\n            File \"C:\\Users\\lenovo\\AppData\\Local\\Temp\\__autograph_generated_file57nxcwqz.py\", line 17, in tf__call\n                scaled_attention, attention_weights = ag__.converted_call(ag__.ld(scaled_dot_product_attention), (ag__.ld(q), ag__.ld(k), ag__.ld(v), ag__.ld(mask)), None, fscope)\n        \n            NameError: Exception encountered when calling layer 'multi_head_attention' (type MultiHeadAttention).\n            \n            in user code:\n            \n                File \"C:\\Users\\lenovo\\AppData\\Local\\Temp\\ipykernel_17992\\2737509367.py\", line 43, in call  *\n                    scaled_attention, attention_weights = scaled_dot_product_attention(q, k, v, mask)\n            \n                NameError: name 'scaled_dot_product_attention' is not defined\n            \n            \n            Call arguments received by layer 'multi_head_attention' (type MultiHeadAttention):\n              • v=tf.Tensor(shape=(None, 60, 384), dtype=float32)\n              • k=tf.Tensor(shape=(None, 60, 384), dtype=float32)\n              • q=tf.Tensor(shape=(None, 60, 384), dtype=float32)\n              • mask=None\n        \n        \n        Call arguments received by layer 'encoder_layer' (type EncoderLayer):\n          • x=tf.Tensor(shape=(None, 60, 384), dtype=float32)\n          • training=True\n          • mask=None\n    \n    \n    Call arguments received by layer 'time_series_transformer' (type TimeSeriesTransformer):\n      • x=tf.Tensor(shape=(None, 60, 33), dtype=float32)\n      • training=True\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 30\u001b[0m\n\u001b[0;32m     27\u001b[0m tensorboard \u001b[38;5;241m=\u001b[39m TensorBoard(log_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./logs\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# Start the search for the best hyperparameter configuration\u001b[39;00m\n\u001b[1;32m---> 30\u001b[0m \u001b[43mtuner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensorboard\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras_tuner\\src\\engine\\base_tuner.py:234\u001b[0m, in \u001b[0;36mBaseTuner.search\u001b[1;34m(self, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[0;32m    232\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_trial_begin(trial)\n\u001b[0;32m    233\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_try_run_and_update_trial(trial, \u001b[38;5;241m*\u001b[39mfit_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_kwargs)\n\u001b[1;32m--> 234\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_trial_end\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    235\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_search_end()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras_tuner\\src\\engine\\base_tuner.py:338\u001b[0m, in \u001b[0;36mBaseTuner.on_trial_end\u001b[1;34m(self, trial)\u001b[0m\n\u001b[0;32m    332\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mon_trial_end\u001b[39m(\u001b[38;5;28mself\u001b[39m, trial):\n\u001b[0;32m    333\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Called at the end of a trial.\u001b[39;00m\n\u001b[0;32m    334\u001b[0m \n\u001b[0;32m    335\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m    336\u001b[0m \u001b[38;5;124;03m        trial: A `Trial` instance.\u001b[39;00m\n\u001b[0;32m    337\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 338\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moracle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mend_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    339\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras_tuner\\src\\engine\\oracle.py:108\u001b[0m, in \u001b[0;36msynchronized.<locals>.wrapped_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m     LOCKS[oracle]\u001b[38;5;241m.\u001b[39macquire()\n\u001b[0;32m    107\u001b[0m     THREADS[oracle] \u001b[38;5;241m=\u001b[39m thread_name\n\u001b[1;32m--> 108\u001b[0m ret_val \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    109\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m need_acquire:\n\u001b[0;32m    110\u001b[0m     THREADS[oracle] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras_tuner\\src\\engine\\oracle.py:586\u001b[0m, in \u001b[0;36mOracle.end_trial\u001b[1;34m(self, trial)\u001b[0m\n\u001b[0;32m    584\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retry(trial):\n\u001b[0;32m    585\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mend_order\u001b[38;5;241m.\u001b[39mappend(trial\u001b[38;5;241m.\u001b[39mtrial_id)\n\u001b[1;32m--> 586\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_consecutive_failures\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    588\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save_trial(trial)\n\u001b[0;32m    589\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras_tuner\\src\\engine\\oracle.py:543\u001b[0m, in \u001b[0;36mOracle._check_consecutive_failures\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    541\u001b[0m     consecutive_failures \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    542\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m consecutive_failures \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_consecutive_failed_trials:\n\u001b[1;32m--> 543\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    544\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of consecutive failures exceeded the limit \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    545\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mof \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_consecutive_failed_trials\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    546\u001b[0m         \u001b[38;5;241m+\u001b[39m (trial\u001b[38;5;241m.\u001b[39mmessage \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    547\u001b[0m     )\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Number of consecutive failures exceeded the limit of 3.\nTraceback (most recent call last):\n  File \"C:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras_tuner\\src\\engine\\base_tuner.py\", line 273, in _try_run_and_update_trial\n    self._run_and_update_trial(trial, *fit_args, **fit_kwargs)\n  File \"C:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras_tuner\\src\\engine\\base_tuner.py\", line 238, in _run_and_update_trial\n    results = self.run_trial(trial, *fit_args, **fit_kwargs)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras_tuner\\src\\tuners\\hyperband.py\", line 427, in run_trial\n    return super().run_trial(trial, *fit_args, **fit_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras_tuner\\src\\engine\\tuner.py\", line 314, in run_trial\n    obj_value = self._build_and_fit_model(trial, *args, **copied_kwargs)\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras_tuner\\src\\engine\\tuner.py\", line 233, in _build_and_fit_model\n    results = self.hypermodel.fit(hp, model, *args, **kwargs)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras_tuner\\src\\engine\\hypermodel.py\", line 149, in fit\n    return model.fit(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 70, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n  File \"C:\\Users\\lenovo\\AppData\\Local\\Temp\\__autograph_generated_filev788uc8h.py\", line 18, in tf__train_function\n    raise\n  File \"C:\\Users\\lenovo\\AppData\\Local\\Temp\\__autograph_generated_filec5ox0ws4.py\", line 31, in tf__call\n    ag__.for_stmt(ag__.converted_call(ag__.ld(range), (ag__.ld(self).num_layers,), None, fscope), None, loop_body, get_state, set_state, ('x',), {'iterate_names': 'i'})\n  File \"C:\\Users\\lenovo\\AppData\\Local\\Temp\\__autograph_generated_filec5ox0ws4.py\", line 29, in loop_body\n    x = ag__.converted_call(ag__.ld(self).enc_layers[ag__.ld(i)], (ag__.ld(x), ag__.ld(training), ag__.ld(padding_mask)), None, fscope)\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\lenovo\\AppData\\Local\\Temp\\__autograph_generated_fileiznkj8k3.py\", line 10, in tf__call\n    attn_output, _ = ag__.converted_call(ag__.ld(self).mha, (ag__.ld(x), ag__.ld(x), ag__.ld(x), ag__.ld(mask)), None, fscope)\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\lenovo\\AppData\\Local\\Temp\\__autograph_generated_file57nxcwqz.py\", line 17, in tf__call\n    scaled_attention, attention_weights = ag__.converted_call(ag__.ld(scaled_dot_product_attention), (ag__.ld(q), ag__.ld(k), ag__.ld(v), ag__.ld(mask)), None, fscope)\n                                                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nNameError: in user code:\n\n    File \"C:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1338, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1322, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1303, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1080, in train_step\n        y_pred = self(x, training=True)\n    File \"C:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\lenovo\\AppData\\Local\\Temp\\__autograph_generated_filec5ox0ws4.py\", line 31, in tf__call\n        ag__.for_stmt(ag__.converted_call(ag__.ld(range), (ag__.ld(self).num_layers,), None, fscope), None, loop_body, get_state, set_state, ('x',), {'iterate_names': 'i'})\n    File \"C:\\Users\\lenovo\\AppData\\Local\\Temp\\__autograph_generated_filec5ox0ws4.py\", line 29, in loop_body\n        x = ag__.converted_call(ag__.ld(self).enc_layers[ag__.ld(i)], (ag__.ld(x), ag__.ld(training), ag__.ld(padding_mask)), None, fscope)\n    File \"C:\\Users\\lenovo\\AppData\\Local\\Temp\\__autograph_generated_fileiznkj8k3.py\", line 10, in tf__call\n        attn_output, _ = ag__.converted_call(ag__.ld(self).mha, (ag__.ld(x), ag__.ld(x), ag__.ld(x), ag__.ld(mask)), None, fscope)\n    File \"C:\\Users\\lenovo\\AppData\\Local\\Temp\\__autograph_generated_file57nxcwqz.py\", line 17, in tf__call\n        scaled_attention, attention_weights = ag__.converted_call(ag__.ld(scaled_dot_product_attention), (ag__.ld(q), ag__.ld(k), ag__.ld(v), ag__.ld(mask)), None, fscope)\n\n    NameError: Exception encountered when calling layer 'time_series_transformer' (type TimeSeriesTransformer).\n    \n    in user code:\n    \n        File \"C:\\Users\\lenovo\\AppData\\Local\\Temp\\ipykernel_17992\\2425982286.py\", line 35, in call  *\n            x = self.enc_layers[i](x, training, padding_mask)\n        File \"C:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 70, in error_handler  **\n            raise e.with_traceback(filtered_tb) from None\n        File \"C:\\Users\\lenovo\\AppData\\Local\\Temp\\__autograph_generated_fileiznkj8k3.py\", line 10, in tf__call\n            attn_output, _ = ag__.converted_call(ag__.ld(self).mha, (ag__.ld(x), ag__.ld(x), ag__.ld(x), ag__.ld(mask)), None, fscope)\n        File \"C:\\Users\\lenovo\\AppData\\Local\\Temp\\__autograph_generated_file57nxcwqz.py\", line 17, in tf__call\n            scaled_attention, attention_weights = ag__.converted_call(ag__.ld(scaled_dot_product_attention), (ag__.ld(q), ag__.ld(k), ag__.ld(v), ag__.ld(mask)), None, fscope)\n    \n        NameError: Exception encountered when calling layer 'encoder_layer' (type EncoderLayer).\n        \n        in user code:\n        \n            File \"C:\\Users\\lenovo\\AppData\\Local\\Temp\\ipykernel_17992\\3993560056.py\", line 15, in call  *\n                attn_output, _ = self.mha(x, x, x, mask)\n            File \"C:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 70, in error_handler  **\n                raise e.with_traceback(filtered_tb) from None\n            File \"C:\\Users\\lenovo\\AppData\\Local\\Temp\\__autograph_generated_file57nxcwqz.py\", line 17, in tf__call\n                scaled_attention, attention_weights = ag__.converted_call(ag__.ld(scaled_dot_product_attention), (ag__.ld(q), ag__.ld(k), ag__.ld(v), ag__.ld(mask)), None, fscope)\n        \n            NameError: Exception encountered when calling layer 'multi_head_attention' (type MultiHeadAttention).\n            \n            in user code:\n            \n                File \"C:\\Users\\lenovo\\AppData\\Local\\Temp\\ipykernel_17992\\2737509367.py\", line 43, in call  *\n                    scaled_attention, attention_weights = scaled_dot_product_attention(q, k, v, mask)\n            \n                NameError: name 'scaled_dot_product_attention' is not defined\n            \n            \n            Call arguments received by layer 'multi_head_attention' (type MultiHeadAttention):\n              • v=tf.Tensor(shape=(None, 60, 384), dtype=float32)\n              • k=tf.Tensor(shape=(None, 60, 384), dtype=float32)\n              • q=tf.Tensor(shape=(None, 60, 384), dtype=float32)\n              • mask=None\n        \n        \n        Call arguments received by layer 'encoder_layer' (type EncoderLayer):\n          • x=tf.Tensor(shape=(None, 60, 384), dtype=float32)\n          • training=True\n          • mask=None\n    \n    \n    Call arguments received by layer 'time_series_transformer' (type TimeSeriesTransformer):\n      • x=tf.Tensor(shape=(None, 60, 33), dtype=float32)\n      • training=True\n\n"
     ]
    }
   ],
   "source": [
    "import kerastuner as kt\n",
    "\n",
    "def build_hypermodel(hp):\n",
    "    num_layers = hp.Int('num_layers', min_value=2, max_value=6, step=1)\n",
    "    d_model = hp.Int('d_model', min_value=64, max_value=512, step=64)\n",
    "    num_heads = hp.Int('num_heads', min_value=2, max_value=8, step=2)\n",
    "    dff = hp.Int('dff', min_value=128, max_value=2048, step=128)\n",
    "    rate = hp.Float('rate', min_value=0.1, max_value=0.5, step=0.1)\n",
    "\n",
    "    model = TimeSeriesTransformer(num_layers=num_layers, d_model=d_model, \n",
    "                                  num_heads=num_heads, dff=dff, rate=rate)\n",
    "\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
    "\n",
    "    return model\n",
    "\n",
    "# Initialize the tuner\n",
    "tuner = kt.Hyperband(build_hypermodel,\n",
    "                     objective='val_loss',\n",
    "                     max_epochs=10,\n",
    "                     factor=3,\n",
    "                     directory='transformer_tuning',\n",
    "                     project_name='stock_prediction')\n",
    "\n",
    "# Define callbacks (e.g., EarlyStopping and TensorBoard)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3)\n",
    "tensorboard = TensorBoard(log_dir='./logs')\n",
    "\n",
    "# Start the search for the best hyperparameter configuration\n",
    "tuner.search(train_dataset, validation_data=val_dataset, epochs=50, callbacks=[early_stopping, tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2d6278ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the train and validation sets for final training\n",
    "X_combined = np.concatenate((X_train_reshaped, X_val_reshaped), axis=0)\n",
    "y_combined = np.concatenate((y_train, y_val), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f1fbaebe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "117/117 [==============================] - 52s 406ms/step - loss: 6.7048e-04\n",
      "Epoch 2/50\n",
      "117/117 [==============================] - 48s 407ms/step - loss: 7.0178e-04\n",
      "Epoch 3/50\n",
      "117/117 [==============================] - 45s 386ms/step - loss: 6.8226e-04\n",
      "Epoch 4/50\n",
      "117/117 [==============================] - 49s 418ms/step - loss: 6.5276e-04\n",
      "Epoch 5/50\n",
      "117/117 [==============================] - 49s 416ms/step - loss: 5.0751e-04\n",
      "Epoch 6/50\n",
      "117/117 [==============================] - 55s 469ms/step - loss: 5.8488e-04\n",
      "Epoch 7/50\n",
      "117/117 [==============================] - 52s 441ms/step - loss: 5.4131e-04\n",
      "Epoch 8/50\n",
      "117/117 [==============================] - 47s 405ms/step - loss: 4.9486e-04\n",
      "Epoch 9/50\n",
      "117/117 [==============================] - 48s 407ms/step - loss: 5.2051e-04\n",
      "Epoch 10/50\n",
      "117/117 [==============================] - 61s 525ms/step - loss: 5.4825e-04\n",
      "Epoch 11/50\n",
      "117/117 [==============================] - 56s 481ms/step - loss: 5.5471e-04\n",
      "Epoch 12/50\n",
      "117/117 [==============================] - 51s 435ms/step - loss: 4.7420e-04\n",
      "Epoch 13/50\n",
      "117/117 [==============================] - 54s 463ms/step - loss: 5.3164e-04\n",
      "Epoch 14/50\n",
      "117/117 [==============================] - 59s 500ms/step - loss: 7.1406e-04\n",
      "Epoch 15/50\n",
      "117/117 [==============================] - 56s 482ms/step - loss: 5.0678e-04\n",
      "Epoch 16/50\n",
      "117/117 [==============================] - 54s 459ms/step - loss: 4.9851e-04\n",
      "Epoch 17/50\n",
      "117/117 [==============================] - 50s 426ms/step - loss: 4.5826e-04\n",
      "Epoch 18/50\n",
      "117/117 [==============================] - 52s 445ms/step - loss: 5.0813e-04\n",
      "Epoch 19/50\n",
      "117/117 [==============================] - 54s 465ms/step - loss: 6.4324e-04\n",
      "Epoch 20/50\n",
      "117/117 [==============================] - 57s 491ms/step - loss: 4.8757e-04\n",
      "Epoch 21/50\n",
      "117/117 [==============================] - 55s 471ms/step - loss: 4.8166e-04\n",
      "Epoch 22/50\n",
      "117/117 [==============================] - 52s 444ms/step - loss: 4.7293e-04\n",
      "Epoch 23/50\n",
      "117/117 [==============================] - 51s 431ms/step - loss: 4.6638e-04\n",
      "Epoch 24/50\n",
      "117/117 [==============================] - 60s 510ms/step - loss: 4.9749e-04\n",
      "Epoch 25/50\n",
      "117/117 [==============================] - 59s 504ms/step - loss: 4.5459e-04\n",
      "Epoch 26/50\n",
      "117/117 [==============================] - 65s 557ms/step - loss: 4.6820e-04\n",
      "Epoch 27/50\n",
      "117/117 [==============================] - 64s 546ms/step - loss: 4.5870e-04\n",
      "Epoch 28/50\n",
      "117/117 [==============================] - 65s 553ms/step - loss: 4.9996e-04\n",
      "Epoch 29/50\n",
      "117/117 [==============================] - 96s 821ms/step - loss: 5.0068e-04\n",
      "Epoch 30/50\n",
      "117/117 [==============================] - 93s 793ms/step - loss: 4.6563e-04\n",
      "Epoch 31/50\n",
      "117/117 [==============================] - 95s 816ms/step - loss: 4.4432e-04\n",
      "Epoch 32/50\n",
      "117/117 [==============================] - 93s 793ms/step - loss: 4.7460e-04\n",
      "Epoch 33/50\n",
      "117/117 [==============================] - 115s 986ms/step - loss: 4.6352e-04\n",
      "Epoch 34/50\n",
      "117/117 [==============================] - 121s 1s/step - loss: 4.9788e-04\n",
      "Epoch 35/50\n",
      "117/117 [==============================] - 115s 981ms/step - loss: 4.4907e-04\n",
      "Epoch 36/50\n",
      "117/117 [==============================] - 116s 991ms/step - loss: 5.0380e-04\n",
      "Epoch 37/50\n",
      "117/117 [==============================] - 115s 982ms/step - loss: 4.2055e-04\n",
      "Epoch 38/50\n",
      "117/117 [==============================] - 115s 980ms/step - loss: 4.2692e-04\n",
      "Epoch 39/50\n",
      "117/117 [==============================] - 111s 944ms/step - loss: 4.4079e-04\n",
      "Epoch 40/50\n",
      "117/117 [==============================] - 109s 934ms/step - loss: 4.1013e-04\n",
      "Epoch 41/50\n",
      "117/117 [==============================] - 103s 879ms/step - loss: 4.2432e-04\n",
      "Epoch 42/50\n",
      "117/117 [==============================] - 106s 907ms/step - loss: 4.5204e-04\n",
      "Epoch 43/50\n",
      "117/117 [==============================] - 106s 909ms/step - loss: 4.5864e-04\n",
      "Epoch 44/50\n",
      "117/117 [==============================] - 71s 605ms/step - loss: 4.1368e-04\n",
      "Epoch 45/50\n",
      "117/117 [==============================] - 96s 817ms/step - loss: 4.2749e-04\n",
      "Epoch 46/50\n",
      "117/117 [==============================] - 89s 760ms/step - loss: 4.1109e-04\n",
      "Epoch 47/50\n",
      "117/117 [==============================] - 94s 807ms/step - loss: 3.9192e-04\n",
      "Epoch 48/50\n",
      "117/117 [==============================] - 94s 802ms/step - loss: 4.1884e-04\n",
      "Epoch 49/50\n",
      "117/117 [==============================] - 90s 772ms/step - loss: 4.5268e-04\n",
      "Epoch 50/50\n",
      "117/117 [==============================] - 91s 778ms/step - loss: 4.0423e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x17600094cd0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the best model on the combined dataset\n",
    "best_model.fit(X_combined, y_combined, epochs=50, batch_size=32, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a4d0a154",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best model is saved to LSTM_Model/best_lstm_model.h5\n"
     ]
    }
   ],
   "source": [
    "# After training, save the best model to an HDF5 file\n",
    "best_model_path = 'LSTM_Model/best_lstm_model.h5'  # Replace with your desired path\n",
    "best_model.save(best_model_path)\n",
    "\n",
    "print(f\"The best model is saved to {best_model_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d33c028",
   "metadata": {},
   "source": [
    "### Best model loss and prediction for test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9cfcdc7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the test set\n",
    "test_loss = best_model.evaluate(X_test_reshaped, y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "86581fc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - 15s 329ms/step\n"
     ]
    }
   ],
   "source": [
    "# Calculate predictions to evaluate other metrics such as R^2 or MAE\n",
    "y_pred = best_model.predict(X_test_reshaped)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fded662b",
   "metadata": {},
   "source": [
    "### Getting model and result info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "edc509d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.000555491482373327\n",
      "R^2 Score: 0.9923823291490315\n",
      "Mean Absolute Error: 0.011540712830362215\n",
      "Mean Squared Error: 0.000555491405254933\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Assuming y_test and y_pred are already defined\n",
    "# You can replace them with your actual test and prediction data\n",
    "\n",
    "# Calculate R^2 score\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Calculate MAE\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "# Calculate MSE\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "# Calculate RMSE\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "# Calculate MAPE\n",
    "# Assuming y_pred is the array you provided\n",
    "y_pred = y_pred.flatten()\n",
    "\n",
    "# Assuming test_loss is defined\n",
    "print(f\"Test Loss: {test_loss}\")\n",
    "print(f\"R^2 Score: {r2}\")\n",
    "print(f\"Mean Absolute Error: {mae}\")\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "print(f\"Root Mean Squared Error: {rmse}\")\n",
    "\n",
    "# Now y_pred is one-dimensional, and you can proceed with calculations like MAPE\n",
    "# Ensure there are no zero elements in y_test to avoid division by zero in MAPE calculation\n",
    "if np.any(y_test == 0):\n",
    "    print(\"Error: y_test contains zero values, which will lead to division by zero in MAPE calculation.\")\n",
    "else:\n",
    "    mape = np.mean(np.abs((y_test - y_pred) / y_test)) * 100\n",
    "    print(f\"Mean Absolute Percentage Error: {mape}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ba99f08f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM Layer 1 Units: 256\n",
      "LSTM Layer 2 Units: 256\n",
      "Dropout Rate: 0.0\n",
      "Learning Rate: 0.0010000000474974513\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "# Load the best model\n",
    "best_model = load_model(best_model_path)\n",
    "\n",
    "# Get the configuration of the model\n",
    "config = best_model.get_config()\n",
    "\n",
    "# Extract the units from the LSTM layers\n",
    "lstm1_units = config['layers'][1]['config']['units']\n",
    "lstm2_units = config['layers'][3]['config']['units']\n",
    "\n",
    "# Extract the dropout rate from the Dropout layer\n",
    "dropout_rate = config['layers'][2]['config']['rate']\n",
    "\n",
    "# Learning rate is part of the optimizer's configuration\n",
    "learning_rate = best_model.optimizer.learning_rate.numpy()\n",
    "\n",
    "# Output the extracted values\n",
    "print(f\"LSTM Layer 1 Units: {lstm1_units}\")\n",
    "print(f\"LSTM Layer 2 Units: {lstm2_units}\")\n",
    "print(f\"Dropout Rate: {dropout_rate}\")\n",
    "print(f\"Learning Rate: {learning_rate}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1cb32e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
