{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1c02272",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d1c02272",
    "outputId": "fecc2e45-125a-4c97-91fc-bc9bd9ab1263"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras-tuner\n",
      "  Downloading keras_tuner-1.4.6-py3-none-any.whl (128 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.9/128.9 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (2.15.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (23.2)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (2.31.0)\n",
      "Collecting kt-legacy (from keras-tuner)\n",
      "  Downloading kt_legacy-1.0.5-py3-none-any.whl (9.6 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (2023.11.17)\n",
      "Installing collected packages: kt-legacy, keras-tuner\n",
      "Successfully installed keras-tuner-1.4.6 kt-legacy-1.0.5\n",
      "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.5.26)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (16.0.6)\n",
      "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.23.5)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.5.0)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.35.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.60.0)\n",
      "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.1)\n",
      "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
      "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.42.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.17.3)\n",
      "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.5.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.3.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2023.11.17)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.5.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-1-cd4ddce39d7a>:5: DeprecationWarning: `import kerastuner` is deprecated, please use `import keras_tuner`.\n",
      "  from kerastuner import RandomSearch\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import keras\n",
    "!pip install keras-tuner\n",
    "!pip install tensorflow\n",
    "from kerastuner import RandomSearch\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01819564",
   "metadata": {
    "id": "01819564"
   },
   "source": [
    "### Preparing train and val dataset for ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71d98483",
   "metadata": {
    "id": "71d98483"
   },
   "outputs": [],
   "source": [
    "# Paths to the train and validation datasets\n",
    "train_data_path = 'train_data.csv'\n",
    "val_data_path = 'val_data.csv'\n",
    "test_data_path = 'test_data.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96bfdbcd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "96bfdbcd",
    "outputId": "7bd25bec-1e34-442f-ba3a-242eaf94905c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2791, 1981)\n",
      "(931, 1981)\n",
      "(931, 1981)\n"
     ]
    }
   ],
   "source": [
    "# Load the datasets\n",
    "train_data = pd.read_csv(train_data_path)\n",
    "val_data = pd.read_csv(val_data_path)\n",
    "test_data = pd.read_csv(test_data_path)\n",
    "print(train_data.shape)\n",
    "print(val_data.shape)\n",
    "print(test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "129143c8",
   "metadata": {
    "id": "129143c8"
   },
   "outputs": [],
   "source": [
    "# Splitting the datasets into features (X) and target (y)\n",
    "X_train = train_data.drop('Output', axis=1)\n",
    "y_train = train_data['Output']\n",
    "X_val = val_data.drop('Output', axis=1)\n",
    "y_val = val_data['Output']\n",
    "X_test = test_data.drop('Output', axis=1)\n",
    "y_test = test_data['Output']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "21e78771",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "21e78771",
    "outputId": "f71e689c-b09c-420a-d4a7-ea887150b610"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (2791, 1980)\n",
      "y_train shape: (2791,)\n",
      "X_val shape: (931, 1980)\n",
      "y_val shape: (931,)\n",
      "X_test shape: (931, 1980)\n",
      "y_test shape: (931,)\n"
     ]
    }
   ],
   "source": [
    "# Check the shapes of the datasets\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"X_val shape:\", X_val.shape)\n",
    "print(\"y_val shape:\", y_val.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_test shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "16ea1907",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "16ea1907",
    "outputId": "abe08336-1ecf-408e-f140-b424a3c660c0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      0.080714\n",
      "1      0.687701\n",
      "2      0.019128\n",
      "3      0.191419\n",
      "4      0.391193\n",
      "         ...   \n",
      "926    0.470977\n",
      "927    0.183726\n",
      "928    0.029032\n",
      "929    0.089227\n",
      "930    0.197472\n",
      "Name: Output, Length: 931, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print (y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e30f6b04",
   "metadata": {
    "id": "e30f6b04"
   },
   "source": [
    "### Building ANN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e70edac",
   "metadata": {
    "id": "2e70edac"
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "279b021f",
   "metadata": {
    "id": "279b021f"
   },
   "outputs": [],
   "source": [
    "# ANN model structure\n",
    "def build_model(hp):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=hp.Int('units_1', min_value=32, max_value=512, step=32),\n",
    "                    activation='relu', input_shape=(1980,)))\n",
    "    model.add(Dropout(rate=hp.Float('dropout_1', min_value=0, max_value=0.5, step=0.1)))\n",
    "    model.add(Dense(units=hp.Int('units_2', min_value=32, max_value=512, step=32),\n",
    "                    activation='relu'))\n",
    "    model.add(Dropout(rate=hp.Float('dropout_2', min_value=0, max_value=0.5, step=0.1)))\n",
    "    model.add(Dense(1))  # Output layer\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1b0f5661",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1b0f5661",
    "outputId": "b4ece09d-292f-4075-b5b2-a5547771f068"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 25 Complete [00h 00m 33s]\n",
      "val_loss: 0.004845475126057863\n",
      "\n",
      "Best val_loss So Far: 0.001386262266896665\n",
      "Total elapsed time: 00h 13m 56s\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter tuner\n",
    "tuner = RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_loss',\n",
    "    max_trials=25,  # Number of trials\n",
    "    executions_per_trial=5,  # Number of models to train per trial\n",
    "    directory='my_dir',\n",
    "    project_name='ann_tuning'\n",
    ")\n",
    "\n",
    "# Hyperparameter search\n",
    "tuner.search(X_train, y_train, epochs=10, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8c1167c9",
   "metadata": {
    "id": "8c1167c9"
   },
   "outputs": [],
   "source": [
    "# Get the optimal hyperparameters\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "# Build the model with the best hyperparameters and train it\n",
    "best_model = tuner.hypermodel.build(best_hps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fb68965f",
   "metadata": {
    "id": "fb68965f"
   },
   "outputs": [],
   "source": [
    "# Combine the train and validation sets for final training\n",
    "X_combined = np.concatenate((X_train, X_val), axis=0)\n",
    "y_combined = np.concatenate((y_train, y_val), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "58e3d365",
   "metadata": {
    "id": "58e3d365"
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "X_combined, y_combined = shuffle(X_combined, y_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e5f265da",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e5f265da",
    "outputId": "8ab067d8-b05a-4f2b-ac1b-06153d8a6328"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "117/117 [==============================] - 1s 3ms/step - loss: 0.7098\n",
      "Epoch 2/50\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 0.0053\n",
      "Epoch 3/50\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 0.0037\n",
      "Epoch 4/50\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 0.0045\n",
      "Epoch 5/50\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 0.0023\n",
      "Epoch 6/50\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 0.0020\n",
      "Epoch 7/50\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 0.0022\n",
      "Epoch 8/50\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 0.0018\n",
      "Epoch 9/50\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 0.0019\n",
      "Epoch 10/50\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 0.0018\n",
      "Epoch 11/50\n",
      "117/117 [==============================] - 0s 4ms/step - loss: 0.0041\n",
      "Epoch 12/50\n",
      "117/117 [==============================] - 0s 4ms/step - loss: 0.0026\n",
      "Epoch 13/50\n",
      "117/117 [==============================] - 0s 4ms/step - loss: 0.0016\n",
      "Epoch 14/50\n",
      "117/117 [==============================] - 1s 4ms/step - loss: 0.0014\n",
      "Epoch 15/50\n",
      "117/117 [==============================] - 0s 4ms/step - loss: 0.0028\n",
      "Epoch 16/50\n",
      "117/117 [==============================] - 1s 4ms/step - loss: 0.0020\n",
      "Epoch 17/50\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 0.0029\n",
      "Epoch 18/50\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 0.0032\n",
      "Epoch 19/50\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 0.0012\n",
      "Epoch 20/50\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 0.0026\n",
      "Epoch 21/50\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 0.0021\n",
      "Epoch 22/50\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 0.0014\n",
      "Epoch 23/50\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 0.0017\n",
      "Epoch 24/50\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 0.0014\n",
      "Epoch 25/50\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 0.0010\n",
      "Epoch 26/50\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 0.0012\n",
      "Epoch 27/50\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 0.0019\n",
      "Epoch 28/50\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 0.0028\n",
      "Epoch 29/50\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 8.2678e-04\n",
      "Epoch 30/50\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 6.8975e-04\n",
      "Epoch 31/50\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 0.0016\n",
      "Epoch 32/50\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 0.0020\n",
      "Epoch 33/50\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 0.0015\n",
      "Epoch 34/50\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 9.6418e-04\n",
      "Epoch 35/50\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 5.1882e-04\n",
      "Epoch 36/50\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 0.0014\n",
      "Epoch 37/50\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 6.1112e-04\n",
      "Epoch 38/50\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 0.0018\n",
      "Epoch 39/50\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 7.3393e-04\n",
      "Epoch 40/50\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 3.7593e-04\n",
      "Epoch 41/50\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 3.6467e-04\n",
      "Epoch 42/50\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 4.7709e-04\n",
      "Epoch 43/50\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 0.0011\n",
      "Epoch 44/50\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 4.8819e-04\n",
      "Epoch 45/50\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 7.2401e-04\n",
      "Epoch 46/50\n",
      "117/117 [==============================] - 1s 4ms/step - loss: 4.3000e-04\n",
      "Epoch 47/50\n",
      "117/117 [==============================] - 0s 4ms/step - loss: 6.7516e-04\n",
      "Epoch 48/50\n",
      "117/117 [==============================] - 0s 4ms/step - loss: 0.0019\n",
      "Epoch 49/50\n",
      "117/117 [==============================] - 0s 4ms/step - loss: 0.0011\n",
      "Epoch 50/50\n",
      "117/117 [==============================] - 0s 4ms/step - loss: 5.7742e-04\n"
     ]
    }
   ],
   "source": [
    "# Train the best model on the combined dataset\n",
    "history = best_model.fit(X_combined, y_combined, epochs=50, batch_size=32, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cfc322df",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cfc322df",
    "outputId": "80d31e21-6174-4aed-dbf9-61e7855671b0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best model is saved to collab_best_ANN_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "# After training, save the best model to an HDF5 file\n",
    "best_model_path = 'collab_best_ANN_model.h5'  # Replace with your desired path\n",
    "best_model.save(best_model_path)\n",
    "\n",
    "print(f\"The best model is saved to {best_model_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "205e23f8",
   "metadata": {
    "id": "205e23f8"
   },
   "source": [
    "### Best model loss and prediction for test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ae6f63c9",
   "metadata": {
    "id": "ae6f63c9"
   },
   "outputs": [],
   "source": [
    "# Evaluate the model on the test set\n",
    "test_loss = best_model.evaluate(X_test, y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4c357a51",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4c357a51",
    "outputId": "4a940d93-1862-45d4-ad6e-1ba49106f45b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "# Calculate predictions to evaluate other metrics such as R^2 or MAE\n",
    "y_pred = best_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb3083c0",
   "metadata": {
    "id": "fb3083c0"
   },
   "source": [
    "### Getting model and result info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6024e760",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6024e760",
    "outputId": "58e7bceb-d508-4aa3-b1a6-577a02b02c3b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0006845650495961308\n",
      "R^2 Score: 0.9906122923210201\n",
      "Mean Absolute Error: 0.020373078590742496\n",
      "Mean Squared Error: 0.0006845650111091428\n",
      "Root Mean Squared Error: 0.026164193301325817\n",
      "Error: y_test contains zero values, which will lead to division by zero in MAPE calculation.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Assuming y_test and y_pred are already defined\n",
    "# You can replace them with your actual test and prediction data\n",
    "\n",
    "# Calculate R^2 score\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Calculate MAE\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "# Calculate MSE\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "# Calculate RMSE\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "# Calculate MAPE\n",
    "# Assuming y_pred is the array you provided\n",
    "y_pred = y_pred.flatten()\n",
    "\n",
    "# Assuming test_loss is defined\n",
    "print(f\"Test Loss: {test_loss}\")\n",
    "print(f\"R^2 Score: {r2}\")\n",
    "print(f\"Mean Absolute Error: {mae}\")\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "print(f\"Root Mean Squared Error: {rmse}\")\n",
    "\n",
    "# Now y_pred is one-dimensional, and you can proceed with calculations like MAPE\n",
    "# Ensure there are no zero elements in y_test to avoid division by zero in MAPE calculation\n",
    "if np.any(y_test == 0):\n",
    "    print(\"Error: y_test contains zero values, which will lead to division by zero in MAPE calculation.\")\n",
    "else:\n",
    "    mape = np.mean(np.abs((y_test - y_pred) / y_test)) * 100\n",
    "    print(f\"Mean Absolute Percentage Error: {mape}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9273cebc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9273cebc",
    "outputId": "c99fc724-7df8-4ad5-bc60-bdeccf9b2b66"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dense Layer 1 Units: 384\n",
      "Dense Layer 2 Units: 96\n",
      "Dropout Layer 1 Rate: 0.0\n",
      "Dropout Layer 2 Rate: 0.0\n",
      "Learning Rate: 0.0010000000474974513\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "# Load the best model\n",
    "best_model = load_model(best_model_path)\n",
    "\n",
    "# Get the configuration of the model\n",
    "config = best_model.get_config()\n",
    "\n",
    "# Extract the units from the Dense layers\n",
    "# Adjust the indices according to your model's architecture\n",
    "dense1_units = config['layers'][1]['config']['units']\n",
    "dense2_units = config['layers'][3]['config']['units']\n",
    "\n",
    "# Extract the dropout rate from the Dropout layer\n",
    "# Adjust the indices if necessary\n",
    "dropout1_rate = config['layers'][2]['config']['rate']\n",
    "dropout2_rate = config['layers'][4]['config']['rate']\n",
    "\n",
    "# Learning rate is part of the optimizer's configuration\n",
    "learning_rate = best_model.optimizer.learning_rate.numpy()\n",
    "\n",
    "# Output the extracted values\n",
    "print(f\"Dense Layer 1 Units: {dense1_units}\")\n",
    "print(f\"Dense Layer 2 Units: {dense2_units}\")\n",
    "print(f\"Dropout Layer 1 Rate: {dropout1_rate}\")\n",
    "print(f\"Dropout Layer 2 Rate: {dropout2_rate}\")\n",
    "print(f\"Learning Rate: {learning_rate}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e66d4bd",
   "metadata": {
    "id": "4e66d4bd"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
