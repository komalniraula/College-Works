{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7dab9f53",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\AppData\\Local\\Temp\\ipykernel_21416\\3497138637.py:3: DeprecationWarning: `import kerastuner` is deprecated, please use `import keras_tuner`.\n",
      "  from kerastuner import RandomSearch\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import keras\n",
    "from kerastuner import RandomSearch\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78add3d3",
   "metadata": {},
   "source": [
    "### Preparing train and val dataset for LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d027d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to the train and validation datasets\n",
    "train_data_path = 'train_data.csv'  \n",
    "val_data_path = 'val_data.csv'  \n",
    "test_data_path = 'test_data.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59454ede",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2791, 1981)\n",
      "(931, 1981)\n"
     ]
    }
   ],
   "source": [
    "# Load the datasets\n",
    "train_data = pd.read_csv(train_data_path)\n",
    "val_data = pd.read_csv(val_data_path)\n",
    "test_data = pd.read_csv(test_data_path)\n",
    "print(train_data.shape)\n",
    "print(val_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dae8e7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the datasets into features (X) and target (y)\n",
    "X_train = train_data.drop('Output', axis=1)\n",
    "y_train = train_data['Output']\n",
    "X_val = val_data.drop('Output', axis=1)\n",
    "y_val = val_data['Output']\n",
    "X_test = test_data.drop('Output', axis=1)\n",
    "y_test = test_data['Output']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29d302c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (2791, 1980)\n",
      "y_train shape: (2791,)\n",
      "X_val shape: (931, 1980)\n",
      "y_val shape: (931,)\n",
      "X_test shape: (931, 1980)\n",
      "y_test shape: (931,)\n"
     ]
    }
   ],
   "source": [
    "# Check the shapes of the datasets\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"X_val shape:\", X_val.shape)\n",
    "print(\"y_val shape:\", y_val.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_test shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c210d5ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      0.080714\n",
      "1      0.687701\n",
      "2      0.019128\n",
      "3      0.191419\n",
      "4      0.391193\n",
      "         ...   \n",
      "926    0.470977\n",
      "927    0.183726\n",
      "928    0.029032\n",
      "929    0.089227\n",
      "930    0.197472\n",
      "Name: Output, Length: 931, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print (y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c88527",
   "metadata": {},
   "source": [
    "### Building lstm model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "030425ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f2a17b35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assuming an equal number of features per day\n",
    "num_days = 60\n",
    "total_features = 1980\n",
    "features_per_day = int(total_features / num_days)\n",
    "features_per_day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ee7731b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the data to (samples, time steps, features)\n",
    "X_train_reshaped = X_train.values.reshape(-1, num_days, features_per_day)\n",
    "X_val_reshaped = X_val.values.reshape(-1, num_days, features_per_day)\n",
    "X_test_reshaped = X_test.values.reshape(-1, num_days, features_per_day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "66342671",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[8.77508802e-01 8.75963586e-01 8.74107413e-01 ... 0.00000000e+00\n",
      "   0.00000000e+00 0.00000000e+00]\n",
      "  [8.83411306e-01 8.85684264e-01 8.85258435e-01 ... 0.00000000e+00\n",
      "   0.00000000e+00 0.00000000e+00]\n",
      "  [8.47678380e-01 8.68316151e-01 8.60032794e-01 ... 0.00000000e+00\n",
      "   0.00000000e+00 0.00000000e+00]\n",
      "  ...\n",
      "  [6.42186773e-01 6.40862657e-01 6.39483947e-01 ... 0.00000000e+00\n",
      "   0.00000000e+00 0.00000000e+00]\n",
      "  [6.67746895e-01 6.62961532e-01 6.49134702e-01 ... 0.00000000e+00\n",
      "   0.00000000e+00 0.00000000e+00]\n",
      "  [6.87238444e-01 7.00086699e-01 6.76880022e-01 ... 0.00000000e+00\n",
      "   0.00000000e+00 0.00000000e+00]]\n",
      "\n",
      " [[3.84374500e-02 3.66728240e-02 3.22461207e-02 ... 0.00000000e+00\n",
      "   0.00000000e+00 0.00000000e+00]\n",
      "  [3.94101290e-02 3.78413780e-02 3.96176240e-02 ... 0.00000000e+00\n",
      "   0.00000000e+00 0.00000000e+00]\n",
      "  [3.85370899e-02 3.68141810e-02 3.72662445e-02 ... 0.00000000e+00\n",
      "   0.00000000e+00 0.00000000e+00]\n",
      "  ...\n",
      "  [3.46843300e-03 1.99313900e-03 7.83793000e-04 ... 0.00000000e+00\n",
      "   1.00000000e+00 0.00000000e+00]\n",
      "  [1.28109000e-03 3.02976000e-03 2.02920700e-03 ... 0.00000000e+00\n",
      "   1.00000000e+00 0.00000000e+00]\n",
      "  [4.18489500e-03 2.64338400e-03 1.26945700e-03 ... 0.00000000e+00\n",
      "   1.00000000e+00 0.00000000e+00]]\n",
      "\n",
      " [[7.20115010e-02 7.30723560e-02 7.39410380e-02 ... 0.00000000e+00\n",
      "   0.00000000e+00 0.00000000e+00]\n",
      "  [7.86114880e-02 7.63424240e-02 7.27196660e-02 ... 0.00000000e+00\n",
      "   0.00000000e+00 0.00000000e+00]\n",
      "  [8.70477040e-02 8.47202070e-02 8.19376520e-02 ... 0.00000000e+00\n",
      "   0.00000000e+00 0.00000000e+00]\n",
      "  ...\n",
      "  [1.83243340e-02 1.72079080e-02 1.77964349e-02 ... 0.00000000e+00\n",
      "   0.00000000e+00 0.00000000e+00]\n",
      "  [2.12945650e-02 1.99172588e-02 1.80032020e-02 ... 0.00000000e+00\n",
      "   0.00000000e+00 0.00000000e+00]\n",
      "  [2.31497740e-02 2.20847390e-02 2.12153123e-02 ... 0.00000000e+00\n",
      "   0.00000000e+00 0.00000000e+00]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[3.99918390e-01 4.04253916e-01 3.98825753e-01 ... 0.00000000e+00\n",
      "   0.00000000e+00 0.00000000e+00]\n",
      "  [3.75036772e-01 3.94867784e-01 3.81038935e-01 ... 0.00000000e+00\n",
      "   0.00000000e+00 0.00000000e+00]\n",
      "  [3.71278908e-01 3.74121228e-01 3.68892543e-01 ... 0.00000000e+00\n",
      "   0.00000000e+00 0.00000000e+00]\n",
      "  ...\n",
      "  [4.07941810e-01 4.03391635e-01 3.99864399e-01 ... 0.00000000e+00\n",
      "   0.00000000e+00 0.00000000e+00]\n",
      "  [4.10826635e-01 4.09507699e-01 4.11332785e-01 ... 0.00000000e+00\n",
      "   0.00000000e+00 0.00000000e+00]\n",
      "  [4.07970279e-01 4.11265243e-01 4.07649438e-01 ... 0.00000000e+00\n",
      "   0.00000000e+00 0.00000000e+00]]\n",
      "\n",
      " [[6.43724080e-02 6.28380800e-02 6.28669520e-02 ... 0.00000000e+00\n",
      "   0.00000000e+00 0.00000000e+00]\n",
      "  [7.02037410e-02 6.79929130e-02 6.67185990e-02 ... 0.00000000e+00\n",
      "   0.00000000e+00 0.00000000e+00]\n",
      "  [6.84434280e-02 6.84970880e-02 6.76081800e-02 ... 0.00000000e+00\n",
      "   0.00000000e+00 0.00000000e+00]\n",
      "  ...\n",
      "  [2.35815485e-02 3.22907439e-02 2.48601915e-02 ... 0.00000000e+00\n",
      "   0.00000000e+00 0.00000000e+00]\n",
      "  [1.62271420e-02 1.63974590e-02 1.66952780e-02 ... 0.00000000e+00\n",
      "   0.00000000e+00 0.00000000e+00]\n",
      "  [1.88367700e-02 1.69817366e-02 1.66087240e-02 ... 0.00000000e+00\n",
      "   0.00000000e+00 0.00000000e+00]]\n",
      "\n",
      " [[1.72169028e-01 1.70302693e-01 1.68736746e-01 ... 0.00000000e+00\n",
      "   0.00000000e+00 0.00000000e+00]\n",
      "  [1.74104898e-01 1.74618806e-01 1.71915196e-01 ... 0.00000000e+00\n",
      "   0.00000000e+00 0.00000000e+00]\n",
      "  [1.63528787e-01 1.69756111e-01 1.66289196e-01 ... 0.00000000e+00\n",
      "   0.00000000e+00 0.00000000e+00]\n",
      "  ...\n",
      "  [2.58111199e-01 2.54664794e-01 2.57464068e-01 ... 0.00000000e+00\n",
      "   0.00000000e+00 0.00000000e+00]\n",
      "  [2.58391141e-01 2.54956933e-01 2.59536552e-01 ... 0.00000000e+00\n",
      "   0.00000000e+00 0.00000000e+00]\n",
      "  [2.53964262e-01 2.54443335e-01 2.57834326e-01 ... 0.00000000e+00\n",
      "   0.00000000e+00 0.00000000e+00]]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train_reshaped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ccdb6aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM model structure\n",
    "def build_lstm_model(hp):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(\n",
    "        units=hp.Int('units', min_value=32, max_value=512, step=32),\n",
    "        input_shape=(num_days, features_per_day),\n",
    "        return_sequences=True))\n",
    "    model.add(Dropout(hp.Float('dropout', min_value=0, max_value=0.5, step=0.1)))\n",
    "    model.add(LSTM(units=hp.Int('units', min_value=32, max_value=512, step=32)))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(\n",
    "        optimizer=Adam(hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])),\n",
    "        loss='mean_squared_error')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b7b2f15f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading Tuner from lstm_tuning\\stock_prediction\\tuner0.json\n"
     ]
    }
   ],
   "source": [
    "tuner = RandomSearch(\n",
    "    build_lstm_model,\n",
    "    objective='val_loss',\n",
    "    max_trials=5,  \n",
    "    executions_per_trial=2,\n",
    "    directory='lstm_tuning',\n",
    "    project_name='stock_prediction')\n",
    "\n",
    "tuner.search(X_train_reshaped, y_train, epochs=10, validation_data=(X_val_reshaped, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b3ba4bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the best model\n",
    "best_model = tuner.get_best_models(num_models=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2d6278ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the train and validation sets for final training\n",
    "X_combined = np.concatenate((X_train_reshaped, X_val_reshaped), axis=0)\n",
    "y_combined = np.concatenate((y_train, y_val), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f1fbaebe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "117/117 [==============================] - 52s 406ms/step - loss: 6.7048e-04\n",
      "Epoch 2/50\n",
      "117/117 [==============================] - 48s 407ms/step - loss: 7.0178e-04\n",
      "Epoch 3/50\n",
      "117/117 [==============================] - 45s 386ms/step - loss: 6.8226e-04\n",
      "Epoch 4/50\n",
      "117/117 [==============================] - 49s 418ms/step - loss: 6.5276e-04\n",
      "Epoch 5/50\n",
      "117/117 [==============================] - 49s 416ms/step - loss: 5.0751e-04\n",
      "Epoch 6/50\n",
      "117/117 [==============================] - 55s 469ms/step - loss: 5.8488e-04\n",
      "Epoch 7/50\n",
      "117/117 [==============================] - 52s 441ms/step - loss: 5.4131e-04\n",
      "Epoch 8/50\n",
      "117/117 [==============================] - 47s 405ms/step - loss: 4.9486e-04\n",
      "Epoch 9/50\n",
      "117/117 [==============================] - 48s 407ms/step - loss: 5.2051e-04\n",
      "Epoch 10/50\n",
      "117/117 [==============================] - 61s 525ms/step - loss: 5.4825e-04\n",
      "Epoch 11/50\n",
      "117/117 [==============================] - 56s 481ms/step - loss: 5.5471e-04\n",
      "Epoch 12/50\n",
      "117/117 [==============================] - 51s 435ms/step - loss: 4.7420e-04\n",
      "Epoch 13/50\n",
      "117/117 [==============================] - 54s 463ms/step - loss: 5.3164e-04\n",
      "Epoch 14/50\n",
      "117/117 [==============================] - 59s 500ms/step - loss: 7.1406e-04\n",
      "Epoch 15/50\n",
      "117/117 [==============================] - 56s 482ms/step - loss: 5.0678e-04\n",
      "Epoch 16/50\n",
      "117/117 [==============================] - 54s 459ms/step - loss: 4.9851e-04\n",
      "Epoch 17/50\n",
      "117/117 [==============================] - 50s 426ms/step - loss: 4.5826e-04\n",
      "Epoch 18/50\n",
      "117/117 [==============================] - 52s 445ms/step - loss: 5.0813e-04\n",
      "Epoch 19/50\n",
      "117/117 [==============================] - 54s 465ms/step - loss: 6.4324e-04\n",
      "Epoch 20/50\n",
      "117/117 [==============================] - 57s 491ms/step - loss: 4.8757e-04\n",
      "Epoch 21/50\n",
      "117/117 [==============================] - 55s 471ms/step - loss: 4.8166e-04\n",
      "Epoch 22/50\n",
      "117/117 [==============================] - 52s 444ms/step - loss: 4.7293e-04\n",
      "Epoch 23/50\n",
      "117/117 [==============================] - 51s 431ms/step - loss: 4.6638e-04\n",
      "Epoch 24/50\n",
      "117/117 [==============================] - 60s 510ms/step - loss: 4.9749e-04\n",
      "Epoch 25/50\n",
      "117/117 [==============================] - 59s 504ms/step - loss: 4.5459e-04\n",
      "Epoch 26/50\n",
      "117/117 [==============================] - 65s 557ms/step - loss: 4.6820e-04\n",
      "Epoch 27/50\n",
      "117/117 [==============================] - 64s 546ms/step - loss: 4.5870e-04\n",
      "Epoch 28/50\n",
      "117/117 [==============================] - 65s 553ms/step - loss: 4.9996e-04\n",
      "Epoch 29/50\n",
      "117/117 [==============================] - 96s 821ms/step - loss: 5.0068e-04\n",
      "Epoch 30/50\n",
      "117/117 [==============================] - 93s 793ms/step - loss: 4.6563e-04\n",
      "Epoch 31/50\n",
      "117/117 [==============================] - 95s 816ms/step - loss: 4.4432e-04\n",
      "Epoch 32/50\n",
      "117/117 [==============================] - 93s 793ms/step - loss: 4.7460e-04\n",
      "Epoch 33/50\n",
      "117/117 [==============================] - 115s 986ms/step - loss: 4.6352e-04\n",
      "Epoch 34/50\n",
      "117/117 [==============================] - 121s 1s/step - loss: 4.9788e-04\n",
      "Epoch 35/50\n",
      "117/117 [==============================] - 115s 981ms/step - loss: 4.4907e-04\n",
      "Epoch 36/50\n",
      "117/117 [==============================] - 116s 991ms/step - loss: 5.0380e-04\n",
      "Epoch 37/50\n",
      "117/117 [==============================] - 115s 982ms/step - loss: 4.2055e-04\n",
      "Epoch 38/50\n",
      "117/117 [==============================] - 115s 980ms/step - loss: 4.2692e-04\n",
      "Epoch 39/50\n",
      "117/117 [==============================] - 111s 944ms/step - loss: 4.4079e-04\n",
      "Epoch 40/50\n",
      "117/117 [==============================] - 109s 934ms/step - loss: 4.1013e-04\n",
      "Epoch 41/50\n",
      "117/117 [==============================] - 103s 879ms/step - loss: 4.2432e-04\n",
      "Epoch 42/50\n",
      "117/117 [==============================] - 106s 907ms/step - loss: 4.5204e-04\n",
      "Epoch 43/50\n",
      "117/117 [==============================] - 106s 909ms/step - loss: 4.5864e-04\n",
      "Epoch 44/50\n",
      "117/117 [==============================] - 71s 605ms/step - loss: 4.1368e-04\n",
      "Epoch 45/50\n",
      "117/117 [==============================] - 96s 817ms/step - loss: 4.2749e-04\n",
      "Epoch 46/50\n",
      "117/117 [==============================] - 89s 760ms/step - loss: 4.1109e-04\n",
      "Epoch 47/50\n",
      "117/117 [==============================] - 94s 807ms/step - loss: 3.9192e-04\n",
      "Epoch 48/50\n",
      "117/117 [==============================] - 94s 802ms/step - loss: 4.1884e-04\n",
      "Epoch 49/50\n",
      "117/117 [==============================] - 90s 772ms/step - loss: 4.5268e-04\n",
      "Epoch 50/50\n",
      "117/117 [==============================] - 91s 778ms/step - loss: 4.0423e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x17600094cd0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the best model on the combined dataset\n",
    "best_model.fit(X_combined, y_combined, epochs=50, batch_size=32, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a4d0a154",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best model is saved to LSTM_Model/best_lstm_model.h5\n"
     ]
    }
   ],
   "source": [
    "# After training, save the best model to an HDF5 file\n",
    "best_model_path = 'LSTM_Model/best_lstm_model.h5'  # Replace with your desired path\n",
    "best_model.save(best_model_path)\n",
    "\n",
    "print(f\"The best model is saved to {best_model_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d33c028",
   "metadata": {},
   "source": [
    "### Best model loss and prediction for test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9cfcdc7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the test set\n",
    "test_loss = best_model.evaluate(X_test_reshaped, y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "86581fc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - 15s 329ms/step\n"
     ]
    }
   ],
   "source": [
    "# Calculate predictions to evaluate other metrics such as R^2 or MAE\n",
    "y_pred = best_model.predict(X_test_reshaped)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fded662b",
   "metadata": {},
   "source": [
    "### Getting model and result info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "edc509d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.000555491482373327\n",
      "R^2 Score: 0.9923823291490315\n",
      "Mean Absolute Error: 0.011540712830362215\n",
      "Mean Squared Error: 0.000555491405254933\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Assuming y_test and y_pred are already defined\n",
    "# You can replace them with your actual test and prediction data\n",
    "\n",
    "# Calculate R^2 score\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Calculate MAE\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "# Calculate MSE\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "# Calculate RMSE\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "# Calculate MAPE\n",
    "# Assuming y_pred is the array you provided\n",
    "y_pred = y_pred.flatten()\n",
    "\n",
    "# Assuming test_loss is defined\n",
    "print(f\"Test Loss: {test_loss}\")\n",
    "print(f\"R^2 Score: {r2}\")\n",
    "print(f\"Mean Absolute Error: {mae}\")\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "print(f\"Root Mean Squared Error: {rmse}\")\n",
    "\n",
    "# Now y_pred is one-dimensional, and you can proceed with calculations like MAPE\n",
    "# Ensure there are no zero elements in y_test to avoid division by zero in MAPE calculation\n",
    "if np.any(y_test == 0):\n",
    "    print(\"Error: y_test contains zero values, which will lead to division by zero in MAPE calculation.\")\n",
    "else:\n",
    "    mape = np.mean(np.abs((y_test - y_pred) / y_test)) * 100\n",
    "    print(f\"Mean Absolute Percentage Error: {mape}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ba99f08f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM Layer 1 Units: 256\n",
      "LSTM Layer 2 Units: 256\n",
      "Dropout Rate: 0.0\n",
      "Learning Rate: 0.0010000000474974513\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "# Load the best model\n",
    "best_model = load_model(best_model_path)\n",
    "\n",
    "# Get the configuration of the model\n",
    "config = best_model.get_config()\n",
    "\n",
    "# Extract the units from the LSTM layers\n",
    "lstm1_units = config['layers'][1]['config']['units']\n",
    "lstm2_units = config['layers'][3]['config']['units']\n",
    "\n",
    "# Extract the dropout rate from the Dropout layer\n",
    "dropout_rate = config['layers'][2]['config']['rate']\n",
    "\n",
    "# Learning rate is part of the optimizer's configuration\n",
    "learning_rate = best_model.optimizer.learning_rate.numpy()\n",
    "\n",
    "# Output the extracted values\n",
    "print(f\"LSTM Layer 1 Units: {lstm1_units}\")\n",
    "print(f\"LSTM Layer 2 Units: {lstm2_units}\")\n",
    "print(f\"Dropout Rate: {dropout_rate}\")\n",
    "print(f\"Learning Rate: {learning_rate}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1cb32e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
